---
title: 'WorkSheet #5'
author: "Malayas, Pauchano, Madayag BSIT2A"
date: "2024-11-09"
output:
  html_document:
    df_print: paged
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# libraries
library(polite)
library(httr)
library(rvest)
library(dplyr)



# Set URL and establish session
imdb_url <- "https://www.imdb.com/chart/toptv/?sort=rank%2Casc"
imdb_session <- bow(imdb_url, user_agent = "Educational")
imdb_session
```


```{r}
# Extract TV show titles and ranks
tv_titles <- read_html(imdb_url) %>%
  html_nodes('.ipc-title__text') %>%
  html_text()
```


```{r}
# transform extracted titles
tv_titles_df <- as.data.frame(tv_titles[3:27], stringsAsFactors = FALSE)
colnames(tv_titles_df) <- "ranked_titles"
```


```{r}
# Rename and delete columns
split_rank_title <- strsplit(as.character(tv_titles_df$ranked_titles), "\\.", fixed = FALSE)
split_rank_title_df <- data.frame(do.call(rbind, split_rank_title), stringsAsFactors = FALSE)
colnames(split_rank_title_df) <- c("Rank", "Title")
split_rank_title_df$Title <- trimws(split_rank_title_df$Title)

ranked_titles_df <- split_rank_title_df
```


```{r}
# Extract ratings, number of votes, episodes, and release years
tv_ratings <- read_html(imdb_url) %>%
  html_nodes('.ipc-rating-star--rating') %>%
  html_text()
```


```{r}
tv_votes <- read_html(imdb_url) %>%
  html_nodes('.ipc-rating-star--voteCount') %>%
  html_text()
cleaned_votes <- gsub('[()]', '', tv_votes)
```


```{r}
# Extract episode counts 
episode_counts <- read_html(imdb_url) %>%
  html_nodes('span.sc-5bc66c50-6.OOdsw.cli-title-metadata-item:nth-of-type(2)') %>%
  html_text()
cleaned_episodes <- gsub('[eps]', '', episode_counts)
episode_counts_num <- as.numeric(cleaned_episodes)
```


```{r}
# Extract release years
release_years <- read_html(imdb_url) %>%
  html_nodes('span.sc-5bc66c50-6.OOdsw.cli-title-metadata-item:nth-of-type(1)') %>%
  html_text()
```




























```{r}
library(polite)
library(rvest)
library(dplyr)
library(ggplot2)

urls <- c(
  'https://www.amazon.com/s?k=gpu&crid=5O6UN0DOCV31&sprefix=gp%2Caps%2C308&ref=nb_sb_noss_2',
  'https://www.amazon.com/s?k=cpu&crid=1V74KAQBN8KR4&sprefix=cpu%2Caps%2C303&ref=nb_sb_noss_1',
  'https://www.amazon.com/s?k=headset&crid=1LVDGNS341ROA&sprefix=head%2Caps%2C306&ref=nb_sb_ss_ts-doa-p_2_4',
  'https://www.amazon.com/s?k=camera&crid=3138M61DHN7M&sprefix=camer%2Caps%2C331&ref=nb_sb_noss_2',
  'https://www.amazon.com/s?k=Watch&crid=ON423ZCM7RT2&sprefix=wa%2Caps%2C332&ref=nb_sb_noss_2'
)

categories <- c("GPU", "CPU", "Headset", "Camera", "Watch")

product_data <- list()
for (i in seq_along(urls)) {
  session <- bow(urls[i], user_agent = "Educational")
  product_name <- scrape(session) %>%
    html_nodes('span.a-size-medium') %>%
    html_text() %>%
    head(30)
  product_price <- scrape(session) %>%
    html_nodes('span.a-price-whole') %>%
    html_text() %>%
    head(30) %>%
    gsub("[^0-9.]", "", .)
  product_rating <- scrape(session) %>%
    html_nodes('i.a-icon-star-small') %>%
    html_nodes('span.a-icon-alt') %>%
    html_text() %>%
    head(30) %>%
    gsub("[^0-9.]", "", .)
  product_rating[product_rating == ""] <- NA
  min_length <- min(length(product_name), length(product_price), length(product_rating))
  product_data[[i]] <- data.frame(
    Product_Name = product_name[1:min_length],
    Price = suppressWarnings(as.numeric(product_price[1:min_length])),
    Rating = suppressWarnings(as.numeric(product_rating[1:min_length])),
    Category = categories[i],
    stringsAsFactors = FALSE
  )
}


final_data <- do.call(rbind, product_data)


final_data$Price[is.na(final_data$Price)] <- 0


final_data_clean <- final_data %>%
  filter(!is.na(Price), !is.na(Rating))


ggplot(final_data_clean, aes(x = Price, y = Rating)) +
  geom_point(color = "blue") +
  facet_wrap(~ Category, scales = "free") +
  labs(title = "Price vs Rating for Each Product Category",
       x = "Price",
       y = "Rating") +
  theme_minimal()

```

